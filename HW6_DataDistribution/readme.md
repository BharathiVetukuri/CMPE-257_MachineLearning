# ğŸ“Š Data Distribution & Model Performance

## ğŸ“Œ Project Overview
This project explores how **modifying data distributions** affects the performance of machine learning models. Using **upsampling & downsampling**, we dynamically alter the distribution of a key feature and observe its impact on model metrics like **F1-score and confusion matrix**. The project includes an **interactive dashboard** that allows real-time experimentation with data distributions.

## ğŸš€ Key Features
âœ… **Modify data distribution** dynamically using a slider  
âœ… **Train & evaluate models** (Random Forest, XGBoost, SVM, MLP)  
âœ… **Interactive confusion matrix** updates based on data changes  
âœ… **Live comparison of F1-score** for different distributions  
âœ… **Dashboard built using Holoviz Panel & HoloViews**  

---
## ğŸ“Š Dataset Used
- **Source:** Fitbit Activity Data (`dailyActivity_merged.csv`)
- **Features:**
  - `TotalSteps`: Total steps taken
  - `VeryActiveMinutes`: Minutes spent in intense physical activity
  - `Calories`: Calories burned (converted to classification target)
  - `ActivityDate`: Timestamp (converted to DateTime)

---

## ğŸ”¬ Data Preprocessing
1ï¸âƒ£ **Converted `ActivityDate` to DateTime**  
2ï¸âƒ£ **Created `TargetClass` using Calories (Low, Medium, High)**  
3ï¸âƒ£ **Feature Selection:** Identified `VeryActiveMinutes` as an important feature  
4ï¸âƒ£ **Implemented data modification techniques** (upsampling/downsampling)  

---

## ğŸ¤– Models Implemented
âœ… **Random Forest (RF)**  
âœ… **XGBoost (XGB)**  
âœ… **Support Vector Machine (SVM)**  
âœ… **Multi-Layer Perceptron (MLP)**  

Each model is evaluated **before and after modifying data distribution** using the **Muller Loop approach**.

---

## ğŸ“Š Performance Metrics
- **F1-score** (Goodness of model predictions)
- **Confusion Matrix** (Visual misclassification analysis)
- **Specificity vs Sensitivity** (Impact of class imbalance)

---

## ğŸ›ï¸ Interactive Dashboard Features
âš¡ **Modify feature distribution dynamically**  
ğŸ“ˆ **Retrain models instantly**  
ğŸ¯ **Live confusion matrix updates**  
ğŸ“Š **Compare model performance interactively**  

<img width="456" alt="image" src="https://github.com/user-attachments/assets/bc4c8c2a-d983-4eb9-9743-b53f5012bbc4" />

---
## ğŸ“Œ Key Learnings & Insights
* Upsampling improved MLP performance significantly, making it more effective for imbalanced datasets.
* XGBoost struggled with modified distributions, proving it is sensitive to data shifts.
* Random Forest remained stable across different distributions, demonstrating robustness.
* SVM performed better with downsampled data, as it benefits from a more balanced dataset.
